### 神经网络的架构

假设我们有这样的网络，这个网络最左边的成为**输入层**，其中的神经元称为**输入神经元**。最右边的，即**输出层**包含**输出神经元**。**中间层**，这些层中的神经元既不是输入也不是输出，被称为**隐藏层**。“隐藏”这个术语实际上仅仅意味着“既非输入也非输出”的含义。比如下面的4层网络有两个隐藏层。

![](/assets/network-architecture.PNG)



设计网络的输入输出层通常是比较直接的。例如，假设我们尝试确定一张手写数字的图像上是否写着“9”。很自然地，我们可以将图片的像素的强度进行编码作为输入神经元来设计网络。如果图像是一个64 x 64的灰度图像，那么我们需要4096=64 x 64 个输入神经元，每个强度取0和1之间合适的值。输出层只需要包含一个神经元，当输出值小于 0.5 时表示“输入的图像不是一个9”，大于0.5时表示“输入的图像是一个9”。

相比较于神经网络中输入输出层的直观设计，隐藏层的设计堪称一门艺术。特别是，通过一些简单的经验法则来总结隐藏层的设计流程是不可行的。相反，神经网络的研究人员已经为隐藏层开发了许多优秀的最优法则，这有助于网络的行为能符合人们期望的那样。

目前为止，我们讨论的神经网络，都是以上一层的输出作为下一层的输入。这种网络被称为**前馈神经网络**。这意味着网络中是没有回路的，信息总是向前传播，从不反向反馈。

然而也有一些神经网络的模型，其中反馈环路是可行的，这些模型被称为递归神经网络。



#### 神经网络的一般含义

神经网络的权重和偏置是被自动学习到的，这样神经网络对我们来说不透明，人们希望在构建人工智能的过程中，也同时能帮助我们理解智能背后的机制。

假设我们要确定一张图是否显示人脸，假定我们要设计一个网络，并为它选择合适的权重和偏置，我们要怎么样做呢？暂时先忘掉神经网络，我们受到启发的一个想法是将这个问题分解成子问题：图像的左上角有一个眼睛吗？右上角有一个眼睛吗？下面中央有一个嘴吗？上面有头发吗？诸如此类。

如果一些问题的回答是“是”，或者仅仅是“可能是”，那么我们可以做出结论这个图像可能是一张脸。相反，如果大多数问题的回答是“不是”，那么这张图可能不是一张脸。

这个想法表明了如果我们能用神经网络来解决这些子问题，那么我们或许可以通过将这些解决子问题的网络结合起来，构成一个人脸检测的神经网络。下面是一个可能的结构。

![](/assets/network-face-subquestions.PNG)



子网络也可以被继续分解。

![](/assets/network-eye-subquestions.PNG)

这些子问题也同样可以继续被分解，并通过多个网络层传递得越来越远。最终我们的子网络可以回答那些只包含若干个像素点的简单问题。

最终我们设计出一个网络，它将一个复杂问题，分解成单像素层面上就可以回答的简单问题。它通过一系列多层结结构来完成，在前面的网络层，它回答关于输入图像非常简单的问题，在后面的网络层，它建立了一个更加复杂和抽象的层级结构，包含这种多层结构——两层或更多隐藏层——的网络被称为**深度神经网络**。

