### 线性回归模型（linear regression）

#### 1.定义

给定数据集，$$T=\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\}$$，其中$$x^{(i)}=(1, x_1, x_2, ..., x_n)^T\in X= R^{n+1}$$，$$y^{(i)}\in Y=R$$，线性回归模型试图学到一个通过属性的线性组合来进行预测的函数，即


$$
f(x)=w_1x_1+w_2x_2+...+w_nx_n+b
$$
一般用向量写成：


$$
f(x)=w^T\cdot x+b
$$
其中$$w=(w_1, x_2, ..., w_n)^T\in R^{n}$$，$$b\in R$$，使得$$f(x)\simeq y$$。

如何确定$$w$$和$$b$$呢，显然关键在于如何衡量$$f(x)$$与$$y$$之间的差别。均方误差是最常用的性能度量，因此我们可以试图让均方误差最小化，即：

$$min_{w,b} L(w,b)=$$

